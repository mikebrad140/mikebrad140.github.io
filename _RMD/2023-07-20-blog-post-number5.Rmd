---
title: "Blog 5: Using R for data science "
author: "Michael Bradshaw"
date: "`r Sys.Date()`" 
---

```{r setup, eval=TRUE, echo=FALSE}
knitr::opts_chunk$set(fig.path = "../images/")
```

```{r createblog, eval=FALSE, echo=FALSE}
rmarkdown::render(
  input = "C://Users//mbradshaw//OneDrive - Research Triangle Institute//Documents//Graduate School Courses//ST 558//Blog Update//mikebrad140.github.io//_RMD//2023-07-20-blog-post-number5.Rmd",
  output_format = "github_document",
  output_dir = "C://Users//mbradshaw//OneDrive - Research Triangle Institute//Documents//Graduate School Courses//ST 558//Blog Update//mikebrad140.github.io//_posts",
  output_options = list(keep_html = FALSE, html_preview=FALSE)
)
```  

## Using R for data science: 

R is clearly a powerful language for data analysis and statistical modeling. During this class, we've explored many of the unique features of R that make it stand out among other statistical programs. In particular, I could appreciate R's support for versatile data structures like lists. Combining loops, lists, and custom functions highlight R's powerful ability to organize, sort, model, and output data. 

I thought the tidyverse packages were powerful tools to enhance data manipulation. Compared to base R, I thought the tidyverse was more intuitive and efficient. Being able to chain operations together was especially helpful in reducing the sometimes cumbersome nature of data processing.

Another area where R excels is data visualization. GGplot2 provides a vast amount of tools for creating high-quality customizable plots. Adding layers to the graphs and chaining them together makes it easy to build an advanced/complex graph. 

Moving forward, I definitely see myself utilizing R to complete data processing and analysis tasks. As someone who has primarily programmed using SAS, having R knowledge as another tool in my toolbox will enhance my skillset and marketability as a professional in the data science field.  Being proficient in multiple programming languages, allows you to adapt to different project requirements.

## Things to do differently in practice now: 

1) One area I plan to start incorporating into my R work is using version control software like Git to track changes in code and collaborate with other programmers. This will help our team manage projects more effectively and avoid potential issues with code management.

2) Another area I plan to change is placing greater emphasis on data cleaning and pre-processing. I feel like we learned the fundamentals needed to investigate our data and understand how to handle items like missing data, outliers, and skewed data. Data quality is crucial for accurate and reliable analysis, so investing more time in these areas will make me a better data scientist. 

3) I plan to incorporate parallel processing using the doParallel package into my programs. We work with big data (like claims data) so, parallel processing  techniques will make the most of computing resources.

4) Finally, I now have more practice with model evaluation and selection techniques. This will help with exploring different algorithms to find the best model.

## what areas of statistics/data science are you thinking about exploring further?

Two areas come to mind: 1) there are many instances where we have large amounts of text to analyze and process so learning natural language processing techniques would be extremely helpful and applicable to my work, and 2) another area I've started to explore in SAS is time series analysis, so I would like to gain that expertise using R. 

My understanding is that R has packages that allow R to handle these areas of analysis and statistical modeling.